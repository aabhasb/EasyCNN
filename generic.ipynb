{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications.densenet import DenseNet169\n",
    "from keras.applications.densenet import DenseNet201\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "import math\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import TensorBoard\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13558302442696943548\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3282324684\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 6761443869010379453\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 950M, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {}\n",
    "params[\"train_dir\"] = \"train\"\n",
    "params[\"test_dir\"] = \"test\"\n",
    "params[\"batch_size\"] = 64\n",
    "params[\"img_width\"] = 221\n",
    "params[\"img_height\"] = 221\n",
    "params[\"train_size\"] = sum([len(files) for r, d, files in os.walk( params[\"train_dir\"] )])\n",
    "params[\"test_size\"] = sum([len(files) for r, d, files in os.walk( params[\"test_dir\"] )])\n",
    "params[\"model\"] = \"ResNet50\"\n",
    "params[\"classes\"] = sum([len(d) for r, d, files in os.walk( params[\"train_dir\"] )])\n",
    "params[\"dense_num\"] = 2\n",
    "params[\"dense1\"] = {\"num\":1024, \"dropout\":0.1, \"pool\":\"avg_poolx\", \"activation\":\"relu\"}\n",
    "params[\"dense2\"] = {\"num\":102, \"activation\":\"softmax\"}\n",
    "params[\"loss\"] = \"categorical_crossentropy\"\n",
    "params[\"optimizer\"] = \"adam\"\n",
    "params[\"metrics\"] = [top_k_categorical_accuracy, 'accuracy']\n",
    "params[\"initial_epoch\"] = 5\n",
    "params[\"final_epoch\"] = 10\n",
    "params[\"workers\"] = 8\n",
    "params[\"step_per_epoch\"] = 80\n",
    "params[\"train_threshold\"] = 0\n",
    "params[\"phase1_optimizer\"] = \"adam\"\n",
    "params[\"phase2_optimizer\"] = SGD(lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8187 images belonging to 102 classes.\n",
      "Found 957 images belonging to 102 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        zoom_range=0.1,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        params[\"train_dir\"],\n",
    "        target_size = (params[\"img_width\"], params[\"img_height\"]),\n",
    "        batch_size = params[\"batch_size\"],\n",
    "        shuffle = True,\n",
    "        class_mode = 'categorical')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        params[\"test_dir\"],\n",
    "        target_size = (params[\"img_width\"], params[\"img_height\"]),\n",
    "        batch_size = params[\"batch_size\"],\n",
    "        shuffle = True,\n",
    "        class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entering\n",
      "2\n",
      "dense1string_name\n",
      "dense1pool avg_poolx\n",
      "dense1sense 1024\n",
      "dropout dense10.1\n",
      "dense2string_name\n",
      "dense2sense 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zxcve\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:48: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "base_model=None\n",
    "if params[\"model\"] == \"InceptionV3\":\n",
    "    params[\"train_threshold\"] = 249\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, input_tensor=None, input_shape=(params[\"img_width\"], params[\"img_height\"], 3))\n",
    "    print(\"par\" + str(params[\"img_width\"]))\n",
    "elif params[\"model\"] == \"xception\":\n",
    "    params[\"train_threshold\"] = 106\n",
    "    base_model = Xception(weights='imagenet', include_top=False, input_tensor=None, input_shape=(params[\"img_width\"], params[\"img_height\"], 3))\n",
    "elif params[\"model\"] == \"InceptionResNetV2\":\n",
    "    params[\"train_threshold\"] = 727\n",
    "    base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_tensor=None, input_shape=(params[\"img_width\"], params[\"img_height\"], 3))\n",
    "elif params[\"model\"] == \"DenseNet121\":\n",
    "    params[\"train_threshold\"] = 403\n",
    "    base_model = DenseNet121(weights='imagenet', include_top=False, input_tensor=None, input_shape=(params[\"img_width\"], params[\"img_height\"], 3))    \n",
    "elif params[\"model\"] == \"DenseNet169\": \n",
    "    params[\"train_threshold\"] = 571\n",
    "    base_model = DenseNet169(weights='imagenet', include_top=False, input_tensor=None, input_shape=(params[\"img_width\"], params[\"img_height\"], 3))    \n",
    "elif params[\"model\"] == \"DenseNet201\":\n",
    "    params[\"train_threshold\"] = 683\n",
    "    base_model = DenseNet201(weights='imagenet', include_top=False, input_tensor=None, input_shape=(params[\"img_width\"], params[\"img_height\"], 3))    \n",
    "elif params[\"model\"] == \"ResNet50\":\n",
    "    params[\"train_threshold\"] = 140\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=None, pooling=None, input_shape=(params[\"img_width\"], params[\"img_height\"], 3))    \n",
    "else:\n",
    "    print(\"unknown model\")\n",
    "count = 0\n",
    "print(\"entering\")\n",
    "modelx = base_model.output\n",
    "print(params[\"dense_num\"])\n",
    "\n",
    "while count < params[\"dense_num\"]:\n",
    "    count += 1\n",
    "    string = \"dense\"+str(count)\n",
    "    print(string + \"string_name\")\n",
    "\n",
    "    if \"pool\" in params[string]:\n",
    "        if params[string][\"pool\"] == \"avg_poolx\":\n",
    "            print(string + \"pool \" + params[string][\"pool\"])\n",
    "            modelx = GlobalAveragePooling2D(name=params[string][\"pool\"])(modelx)\n",
    "    print(string + \"sense \" + str(params[string][\"num\"]))\n",
    "\n",
    "    modelx = Dense(params[string][\"num\"], activation = params[string][\"activation\"])(modelx)\n",
    "    \n",
    "    if \"dropout\" in params[string]:\n",
    "        print(\"dropout \" + string + str(params[string][\"dropout\"]))\n",
    "        modelx = Dropout(params[string][\"dropout\"])(modelx)\n",
    "        \n",
    "model = Model(inputs=base_model.input, output=modelx)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(loss=params[\"loss\"], optimizer=params[\"phase1_optimizer\"], metrics=params[\"metrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbd = TensorBoard(log_dir='./logs_' + params[\"model\"] ,  batch_size=params[\"batch_size\"], write_graph=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file=params[\"model\"] + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "80/80 [==============================] - 186s 2s/step - loss: 1.3838 - top_k_categorical_accuracy: 0.8347 - acc: 0.6954 - val_loss: 5.0486 - val_top_k_categorical_accuracy: 0.0857 - val_acc: 0.0481\n",
      "Epoch 2/5\n",
      "80/80 [==============================] - 180s 2s/step - loss: 0.5036 - top_k_categorical_accuracy: 0.9666 - acc: 0.8615 - val_loss: 5.6967 - val_top_k_categorical_accuracy: 0.0690 - val_acc: 0.0481\n",
      "Epoch 3/5\n",
      "80/80 [==============================] - 180s 2s/step - loss: 0.3386 - top_k_categorical_accuracy: 0.9835 - acc: 0.9061 - val_loss: 6.8228 - val_top_k_categorical_accuracy: 0.1348 - val_acc: 0.0481\n",
      "Epoch 4/5\n",
      "80/80 [==============================] - 180s 2s/step - loss: 0.2125 - top_k_categorical_accuracy: 0.9947 - acc: 0.9376 - val_loss: 6.8630 - val_top_k_categorical_accuracy: 0.1014 - val_acc: 0.0481\n",
      "Epoch 5/5\n",
      "80/80 [==============================] - 181s 2s/step - loss: 0.1961 - top_k_categorical_accuracy: 0.9949 - acc: 0.9426 - val_loss: 6.2322 - val_top_k_categorical_accuracy: 0.1661 - val_acc: 0.0481\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=train_generator,\n",
    "                         steps_per_epoch = params[\"step_per_epoch\"],\n",
    "                         epochs = params[\"initial_epoch\"],\n",
    "                         use_multiprocessing=False,\n",
    "                         max_queue_size=10,\n",
    "                         workers = params[\"workers\"],     \n",
    "                         validation_data = validation_generator,\n",
    "                         callbacks=[tbd ],\n",
    "                         validation_steps = math.ceil(params[\"test_size\"]  / params[\"batch_size\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_top_k_categorical_accuracy', 'val_acc', 'loss', 'top_k_categorical_accuracy', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMv8HWKXWmmYKiMYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24f7e380eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title(params[\"model\"] + ' model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 conv1\n",
      "2 bn_conv1\n",
      "3 activation_1\n",
      "4 max_pooling2d_1\n",
      "5 res2a_branch2a\n",
      "6 bn2a_branch2a\n",
      "7 activation_2\n",
      "8 res2a_branch2b\n",
      "9 bn2a_branch2b\n",
      "10 activation_3\n",
      "11 res2a_branch2c\n",
      "12 res2a_branch1\n",
      "13 bn2a_branch2c\n",
      "14 bn2a_branch1\n",
      "15 add_1\n",
      "16 activation_4\n",
      "17 res2b_branch2a\n",
      "18 bn2b_branch2a\n",
      "19 activation_5\n",
      "20 res2b_branch2b\n",
      "21 bn2b_branch2b\n",
      "22 activation_6\n",
      "23 res2b_branch2c\n",
      "24 bn2b_branch2c\n",
      "25 add_2\n",
      "26 activation_7\n",
      "27 res2c_branch2a\n",
      "28 bn2c_branch2a\n",
      "29 activation_8\n",
      "30 res2c_branch2b\n",
      "31 bn2c_branch2b\n",
      "32 activation_9\n",
      "33 res2c_branch2c\n",
      "34 bn2c_branch2c\n",
      "35 add_3\n",
      "36 activation_10\n",
      "37 res3a_branch2a\n",
      "38 bn3a_branch2a\n",
      "39 activation_11\n",
      "40 res3a_branch2b\n",
      "41 bn3a_branch2b\n",
      "42 activation_12\n",
      "43 res3a_branch2c\n",
      "44 res3a_branch1\n",
      "45 bn3a_branch2c\n",
      "46 bn3a_branch1\n",
      "47 add_4\n",
      "48 activation_13\n",
      "49 res3b_branch2a\n",
      "50 bn3b_branch2a\n",
      "51 activation_14\n",
      "52 res3b_branch2b\n",
      "53 bn3b_branch2b\n",
      "54 activation_15\n",
      "55 res3b_branch2c\n",
      "56 bn3b_branch2c\n",
      "57 add_5\n",
      "58 activation_16\n",
      "59 res3c_branch2a\n",
      "60 bn3c_branch2a\n",
      "61 activation_17\n",
      "62 res3c_branch2b\n",
      "63 bn3c_branch2b\n",
      "64 activation_18\n",
      "65 res3c_branch2c\n",
      "66 bn3c_branch2c\n",
      "67 add_6\n",
      "68 activation_19\n",
      "69 res3d_branch2a\n",
      "70 bn3d_branch2a\n",
      "71 activation_20\n",
      "72 res3d_branch2b\n",
      "73 bn3d_branch2b\n",
      "74 activation_21\n",
      "75 res3d_branch2c\n",
      "76 bn3d_branch2c\n",
      "77 add_7\n",
      "78 activation_22\n",
      "79 res4a_branch2a\n",
      "80 bn4a_branch2a\n",
      "81 activation_23\n",
      "82 res4a_branch2b\n",
      "83 bn4a_branch2b\n",
      "84 activation_24\n",
      "85 res4a_branch2c\n",
      "86 res4a_branch1\n",
      "87 bn4a_branch2c\n",
      "88 bn4a_branch1\n",
      "89 add_8\n",
      "90 activation_25\n",
      "91 res4b_branch2a\n",
      "92 bn4b_branch2a\n",
      "93 activation_26\n",
      "94 res4b_branch2b\n",
      "95 bn4b_branch2b\n",
      "96 activation_27\n",
      "97 res4b_branch2c\n",
      "98 bn4b_branch2c\n",
      "99 add_9\n",
      "100 activation_28\n",
      "101 res4c_branch2a\n",
      "102 bn4c_branch2a\n",
      "103 activation_29\n",
      "104 res4c_branch2b\n",
      "105 bn4c_branch2b\n",
      "106 activation_30\n",
      "107 res4c_branch2c\n",
      "108 bn4c_branch2c\n",
      "109 add_10\n",
      "110 activation_31\n",
      "111 res4d_branch2a\n",
      "112 bn4d_branch2a\n",
      "113 activation_32\n",
      "114 res4d_branch2b\n",
      "115 bn4d_branch2b\n",
      "116 activation_33\n",
      "117 res4d_branch2c\n",
      "118 bn4d_branch2c\n",
      "119 add_11\n",
      "120 activation_34\n",
      "121 res4e_branch2a\n",
      "122 bn4e_branch2a\n",
      "123 activation_35\n",
      "124 res4e_branch2b\n",
      "125 bn4e_branch2b\n",
      "126 activation_36\n",
      "127 res4e_branch2c\n",
      "128 bn4e_branch2c\n",
      "129 add_12\n",
      "130 activation_37\n",
      "131 res4f_branch2a\n",
      "132 bn4f_branch2a\n",
      "133 activation_38\n",
      "134 res4f_branch2b\n",
      "135 bn4f_branch2b\n",
      "136 activation_39\n",
      "137 res4f_branch2c\n",
      "138 bn4f_branch2c\n",
      "139 add_13\n",
      "140 activation_40\n",
      "141 res5a_branch2a\n",
      "142 bn5a_branch2a\n",
      "143 activation_41\n",
      "144 res5a_branch2b\n",
      "145 bn5a_branch2b\n",
      "146 activation_42\n",
      "147 res5a_branch2c\n",
      "148 res5a_branch1\n",
      "149 bn5a_branch2c\n",
      "150 bn5a_branch1\n",
      "151 add_14\n",
      "152 activation_43\n",
      "153 res5b_branch2a\n",
      "154 bn5b_branch2a\n",
      "155 activation_44\n",
      "156 res5b_branch2b\n",
      "157 bn5b_branch2b\n",
      "158 activation_45\n",
      "159 res5b_branch2c\n",
      "160 bn5b_branch2c\n",
      "161 add_15\n",
      "162 activation_46\n",
      "163 res5c_branch2a\n",
      "164 bn5c_branch2a\n",
      "165 activation_47\n",
      "166 res5c_branch2b\n",
      "167 bn5c_branch2b\n",
      "168 activation_48\n",
      "169 res5c_branch2c\n",
      "170 bn5c_branch2c\n",
      "171 add_16\n",
      "172 activation_49\n",
      "173 avg_pool\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)\n",
    "\n",
    "for layer in model.layers[:params[\"train_threshold\"]]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[params[\"train_threshold\"]:]:\n",
    "   layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=params[\"loss\"], optimizer=params[\"phase2_optimizer\"], metrics=params[\"metrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = model.fit_generator(generator=train_generator,\n",
    "                         steps_per_epoch = params[\"step_per_epoch\"] ,\n",
    "                         epochs = params[\"final_epoch\"] ,\n",
    "                         initial_epoch= params[\"initial_epoch\"] ,\n",
    "                         use_multiprocessing=False,\n",
    "                         max_queue_size=10,\n",
    "                         workers = params[\"workers\"],                                  \n",
    "                         validation_data = validation_generator,\n",
    "                         callbacks=[tbd],\n",
    "                         validation_steps = math.ceil(params[\"test_size\"]  / params[\"batch_size\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_\" + params[\"model\"] + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history1.history.keys())\n",
    "plt.plot(history1.history['acc'])\n",
    "plt.plot(history1.history['val_acc'])\n",
    "plt.title(params[\"model\"] + ' model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(params[\"model\"] + \".history0\", \"wb\") as f:\n",
    "    pickle.dump(history.history, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(params[\"model\"] + \".history1\", \"wb\") as f:\n",
    "    pickle.dump(history1.history, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
