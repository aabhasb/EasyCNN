{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications.densenet import DenseNet169\n",
    "from keras.applications.densenet import DenseNet201\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "import math\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import TensorBoard\n",
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16282724938913288360\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3282324684\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 18101270969709188330\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 950M, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {}\n",
    "params[\"train_dir\"] = \"train\"\n",
    "params[\"test_dir\"] = \"test\"\n",
    "params[\"batch_size\"] = 64\n",
    "params[\"img_width\"] = 221\n",
    "params[\"img_height\"] = 221\n",
    "\n",
    "\n",
    "params[\"loss\"] = \"categorical_crossentropy\"\n",
    "params[\"metrics\"] = ['top_k_categorical_accuracy', 'accuracy']\n",
    "params[\"initial_epoch\"] = 5\n",
    "params[\"final_epoch\"] = 10\n",
    "params[\"workers\"] = 8\n",
    "params[\"step_per_epoch\"] = 80\n",
    "params[\"train_threshold\"] = 0\n",
    "params[\"phase1_optimizer\"] = \"adam\"\n",
    "\n",
    "params[\"model_list\"] = [\"InceptionV3\", \"xception\", \"InceptionResNetV2\", \"DenseNet121\", \"DenseNet169\", \"DenseNet201\"]\n",
    "params[\"dropout_list\"] = [0.1, 0.2, 0.3]\n",
    "params[\"dense_list\"] = [512, 1024]\n",
    "\n",
    "with open(\"params.json\", \"w\") as f:\n",
    "    json.dump(params, f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "\n",
    "with open(\"params.json\", \"r\") as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "params[\"train_size\"] = sum([len(files) for r, d, files in os.walk( params[\"train_dir\"] )])\n",
    "params[\"test_size\"] = sum([len(files) for r, d, files in os.walk( params[\"test_dir\"] )])\n",
    "params[\"classes\"] = sum([len(d) for r, d, files in os.walk( params[\"train_dir\"] )])\n",
    "params[\"phase2_optimizer\"] = SGD(lr=0.001, momentum=0.9)\n",
    "params[\"dense_num\"] = 2\n",
    "params[\"dense2\"] = {\"num\":params[\"classes\"], \"activation\":\"softmax\"}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8187 images belonging to 102 classes.\n",
      "Found 957 images belonging to 102 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        zoom_range=0.1,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        params[\"train_dir\"],\n",
    "        target_size = (params[\"img_width\"], params[\"img_height\"]),\n",
    "        batch_size = params[\"batch_size\"],\n",
    "        shuffle = True,\n",
    "        class_mode = 'categorical')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        params[\"test_dir\"],\n",
    "        target_size = (params[\"img_width\"], params[\"img_height\"]),\n",
    "        batch_size = params[\"batch_size\"],\n",
    "        shuffle = True,\n",
    "        class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    base_model=None\n",
    "    if params[\"model\"] == \"InceptionV3\":\n",
    "        params[\"train_threshold\"] = 249\n",
    "        base_model = InceptionV3(weights='imagenet', include_top=False, input_tensor=None, input_shape=(params[\"img_width\"], params[\"img_height\"], 3))\n",
    "    elif params[\"model\"] == \"xception\":\n",
    "        params[\"train_threshold\"] = 106\n",
    "        base_model = Xception(weights='imagenet', include_top=False, input_tensor=None, input_shape=(params[\"img_width\"], params[\"img_height\"], 3))\n",
    "    elif params[\"model\"] == \"InceptionResNetV2\":\n",
    "        params[\"train_threshold\"] = 727\n",
    "        base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_tensor=None, input_shape=(params[\"img_width\"], params[\"img_height\"], 3))\n",
    "    elif params[\"model\"] == \"DenseNet121\":\n",
    "        params[\"train_threshold\"] = 403\n",
    "        base_model = DenseNet121(weights='imagenet', include_top=False, input_tensor=None, input_shape=(params[\"img_width\"], params[\"img_height\"], 3))    \n",
    "    elif params[\"model\"] == \"DenseNet169\": \n",
    "        params[\"train_threshold\"] = 571\n",
    "        base_model = DenseNet169(weights='imagenet', include_top=False, input_tensor=None, input_shape=(params[\"img_width\"], params[\"img_height\"], 3))    \n",
    "    elif params[\"model\"] == \"DenseNet201\":\n",
    "        params[\"train_threshold\"] = 683\n",
    "        base_model = DenseNet201(weights='imagenet', include_top=False, input_tensor=None, input_shape=(params[\"img_width\"], params[\"img_height\"], 3))    \n",
    "    elif params[\"model\"] == \"ResNet50\":\n",
    "        params[\"train_threshold\"] = 140\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=None, pooling=None, input_shape=(params[\"img_width\"], params[\"img_height\"], 3))    \n",
    "    else:\n",
    "        print(\"unknown model\")\n",
    "\n",
    "    count = 0\n",
    "    modelx = base_model.output\n",
    "\n",
    "    while count < params[\"dense_num\"]:\n",
    "        count += 1\n",
    "        string = \"dense\"+str(count)\n",
    "\n",
    "        if \"pool\" in params[string]:\n",
    "            if params[string][\"pool\"] == \"avg_poolx\":\n",
    "                modelx = GlobalAveragePooling2D(name=params[string][\"pool\"])(modelx)\n",
    "\n",
    "        modelx = Dense(params[string][\"num\"], activation = params[string][\"activation\"])(modelx)\n",
    "    \n",
    "        if \"dropout\" in params[string]:\n",
    "            modelx = Dropout(params[string][\"dropout\"])(modelx)\n",
    "        \n",
    "    model = Model(inputs=base_model.input, output=modelx)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(loss=params[\"loss\"], optimizer=params[\"phase1_optimizer\"], metrics=params[\"metrics\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class log_history(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        pass\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        params[\"history\"][\"val_top_k_categorical_accuracy\"].append(logs.get('val_top_k_categorical_accuracy'))\n",
    "        params[\"history\"][\"val_loss\"].append(logs.get('val_loss'))\n",
    "        params[\"history\"][\"loss\"].append(logs.get('loss'))\n",
    "        params[\"history\"][\"top_k_categorical_accuracy\"].append(logs.get('top_k_categorical_accuracy'))\n",
    "        params[\"history\"][\"acc\"].append(logs.get('acc'))\n",
    "        params[\"history\"][\"val_acc\"].append(logs.get('val_acc')) \n",
    "#        print(params[\"history\"])\n",
    "        with open(params[\"historypath\"] + \"/epoch.json\", \"w\") as f:\n",
    "            json.dump(params[\"history\"], f)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zxcve\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:43: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 3.5015 - top_k_categorical_accuracy: 0.4498 - acc: 0.2993{'val_top_k_categorical_accuracy': [0.70846394934499779], 'val_loss': [2.2673402368212692], 'loss': [3.4422397017478943], 'top_k_categorical_accuracy': [0.46171875000000001], 'acc': [0.30937500000000001], 'val_acc': [0.54545454470715182]}\n",
      "20/20 [==============================] - 48s 2s/step - loss: 3.4422 - top_k_categorical_accuracy: 0.4617 - acc: 0.3094 - val_loss: 2.2673 - val_top_k_categorical_accuracy: 0.7085 - val_acc: 0.5455\n",
      "Epoch 2/2\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 2.0167 - top_k_categorical_accuracy: 0.7763 - acc: 0.5732{'val_top_k_categorical_accuracy': [0.70846394934499779, 0.83490072995766829], 'val_loss': [2.2673402368212692, 1.484239880194111], 'loss': [3.4422397017478943, 2.0064731359481813], 'top_k_categorical_accuracy': [0.46171875000000001, 0.77734375], 'acc': [0.30937500000000001, 0.578125], 'val_acc': [0.54545454470715182, 0.67189132662776119]}\n",
      "20/20 [==============================] - 43s 2s/step - loss: 2.0065 - top_k_categorical_accuracy: 0.7773 - acc: 0.5781 - val_loss: 1.4842 - val_top_k_categorical_accuracy: 0.8349 - val_acc: 0.6719\n",
      "Epoch 3/4\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 1.4366 - top_k_categorical_accuracy: 0.8577 - acc: 0.7081{'val_top_k_categorical_accuracy': [0.70846394934499779, 0.83490072995766829, 0.90491118195662301], 'val_loss': [2.2673402368212692, 1.484239880194111, 1.1124152477009295], 'loss': [3.4422397017478943, 2.0064731359481813, 1.4197714567184447], 'top_k_categorical_accuracy': [0.46171875000000001, 0.77734375, 0.86250000000000004], 'acc': [0.30937500000000001, 0.578125, 0.70781249999999996], 'val_acc': [0.54545454470715182, 0.67189132662776119, 0.76071055350258809]}\n",
      "20/20 [==============================] - 50s 2s/step - loss: 1.4198 - top_k_categorical_accuracy: 0.8625 - acc: 0.7078 - val_loss: 1.1124 - val_top_k_categorical_accuracy: 0.9049 - val_acc: 0.7607\n",
      "Epoch 4/4\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 1.1944 - top_k_categorical_accuracy: 0.9093 - acc: 0.7373{'val_top_k_categorical_accuracy': [0.70846394934499779, 0.83490072995766829, 0.90491118195662301, 0.92789968515015442], 'val_loss': [2.2673402368212692, 1.484239880194111, 1.1124152477009295, 0.93451953569549751], 'loss': [3.4422397017478943, 2.0064731359481813, 1.4197714567184447, 1.179422677638484], 'top_k_categorical_accuracy': [0.46171875000000001, 0.77734375, 0.86250000000000004, 0.91137254841187421], 'acc': [0.30937500000000001, 0.578125, 0.70781249999999996, 0.74274509827295943], 'val_acc': [0.54545454470715182, 0.67189132662776119, 0.76071055350258809, 0.78474399257478544]}\n",
      "20/20 [==============================] - 48s 2s/step - loss: 1.1794 - top_k_categorical_accuracy: 0.9115 - acc: 0.7426 - val_loss: 0.9345 - val_top_k_categorical_accuracy: 0.9279 - val_acc: 0.7847\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-0dde33a34f24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m                          \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                          \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtbd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_history\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                          validation_steps = math.ceil(params[\"test_size\"]  / params[\"batch_size\"]))  \n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"train_threshold\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2072\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2073\u001b[0m             \u001b[0mcallback_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2074\u001b[1;33m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2075\u001b[0m         callbacks.set_params({\n\u001b[0;32m   2076\u001b[0m             \u001b[1;34m'epochs'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mset_model\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mset_model\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    716\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m             self.writer = tf.summary.FileWriter(self.log_dir,\n\u001b[1;32m--> 718\u001b[1;33m                                                 self.sess.graph)\n\u001b[0m\u001b[0;32m    719\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\summary\\writer\\writer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, logdir, graph, max_queue, flush_secs, graph_def, filename_suffix)\u001b[0m\n\u001b[0;32m    335\u001b[0m     event_writer = EventFileWriter(logdir, max_queue, flush_secs,\n\u001b[0;32m    336\u001b[0m                                    filename_suffix)\n\u001b[1;32m--> 337\u001b[1;33m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent_writer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\summary\\writer\\writer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, event_writer, graph, graph_def)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mgraph_def\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m       \u001b[1;31m# Calling it with both graph and graph_def for backward compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m       \u001b[1;31m# Also export the meta_graph_def in this case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m       \u001b[1;31m# graph may itself be a graph_def due to positional arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\summary\\writer\\writer.py\u001b[0m in \u001b[0;36madd_graph\u001b[1;34m(self, graph, global_step, graph_def)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m       \u001b[1;31m# Serialize the graph with additional info.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m       \u001b[0mtrue_graph_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_graph_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madd_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_write_plugin_assets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     elif (isinstance(graph, graph_pb2.GraphDef) or\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_def\u001b[1;34m(self, from_version, add_shapes)\u001b[0m\n\u001b[0;32m   2771\u001b[0m     \"\"\"\n\u001b[0;32m   2772\u001b[0m     \u001b[1;31m# pylint: enable=line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2773\u001b[1;33m     \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrom_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2774\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_def\u001b[1;34m(self, from_version, add_shapes)\u001b[0m\n\u001b[0;32m   2724\u001b[0m         \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nodes_by_id\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mop_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2725\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfrom_version\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mop_id\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mfrom_version\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2726\u001b[1;33m           \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2727\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0madd_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2728\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[1;34m\"_output_shapes\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\containers.py\u001b[0m in \u001b[0;36mextend\u001b[1;34m(self, elem_seq)\u001b[0m\n\u001b[0;32m    387\u001b[0m       \u001b[0mnew_element\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmessage_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m       \u001b[0mnew_element\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SetListener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlistener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m       \u001b[0mnew_element\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMergeFrom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m       \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_element\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[0mlistener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModified\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36mMergeFrom\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m   1242\u001b[0m           \u001b[0mfield_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfield\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m           \u001b[0mfields\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfield_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1244\u001b[1;33m         \u001b[0mfield_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMergeFrom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1245\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0mfield\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpp_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mCPPTYPE_MESSAGE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1246\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_present_in_parent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\containers.py\u001b[0m in \u001b[0;36mMergeFrom\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;31m# self._message_listener.Modified() not required here, because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m     \u001b[1;31m# mutations to submessages already propagate.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\protobuf\\message.py\u001b[0m in \u001b[0;36mCopyFrom\u001b[1;34m(self, other_msg)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mother_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m       \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMergeFrom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\u001b[0m in \u001b[0;36m_Clear\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1293\u001b[0m   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unknown_fields\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_oneofs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1295\u001b[1;33m   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Modified\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for model_name in params[\"model_list\"]:\n",
    "    params[\"model\"] = model_name\n",
    "    best_accuracy = 0\n",
    "\n",
    "    for dropout_num in params[\"dropout_list\"]:\n",
    "        for dense_num in params[\"dense_list\"]:\n",
    "            params[\"dense1\"] = {\"num\":dense_num, \"dropout\":dropout_num, \"pool\":\"avg_poolx\", \"activation\":\"relu\"}\n",
    "            params[\"tensorpath\"] = \"./tensor/\" + params['model'] + \"/\" + \"dense_\"+str(dense_num) + \"_dropout_\" + str(dropout_num)\n",
    "            params[\"historypath\"] = \"./history/\" + params['model'] + \"/\" + \"dense_\"+str(dense_num) + \"_dropout_\" + str(dropout_num)\n",
    "            tbd = TensorBoard(log_dir=params[\"tensorpath\"] ,  batch_size=params[\"batch_size\"], write_graph=True )\n",
    "            params[\"history\"] = {}\n",
    "            params[\"history\"][\"val_top_k_categorical_accuracy\"] = []\n",
    "            params[\"history\"][\"val_loss\"] = []\n",
    "            params[\"history\"][\"loss\"] = []\n",
    "            params[\"history\"][\"top_k_categorical_accuracy\"] = []\n",
    "            params[\"history\"][\"acc\"] = []\n",
    "            params[\"history\"][\"val_acc\"] = []            \n",
    "            model = create_model()\n",
    "            epoch_history = log_history()\n",
    "            if not os.path.exists(params['historypath']):\n",
    "                os.makedirs(params['historypath'])\n",
    "            \n",
    "            history = model.fit_generator(generator=train_generator,\n",
    "                         steps_per_epoch = params[\"step_per_epoch\"],\n",
    "                         epochs = params[\"initial_epoch\"],\n",
    "                         use_multiprocessing=False,\n",
    "                         max_queue_size=10,\n",
    "                         workers = params[\"workers\"],     \n",
    "                         validation_data = validation_generator,\n",
    "                         callbacks=[tbd, epoch_history],\n",
    "                         validation_steps = math.ceil(params[\"test_size\"]  / params[\"batch_size\"]))  \n",
    "            \n",
    "            for layer in model.layers[:params[\"train_threshold\"]]:\n",
    "               layer.trainable = False\n",
    "            for layer in model.layers[params[\"train_threshold\"]:]:\n",
    "               layer.trainable = True\n",
    "                        \n",
    "            model.compile(loss=params[\"loss\"], optimizer=params[\"phase2_optimizer\"], metrics=params[\"metrics\"])\n",
    "            history1 = model.fit_generator(generator=train_generator,\n",
    "                         steps_per_epoch = params[\"step_per_epoch\"] ,\n",
    "                         epochs = params[\"final_epoch\"] ,\n",
    "                         initial_epoch= params[\"initial_epoch\"] ,\n",
    "                         use_multiprocessing=False,\n",
    "                         max_queue_size=10,\n",
    "                         workers = params[\"workers\"],                                  \n",
    "                         validation_data = validation_generator,\n",
    "                         callbacks=[tbd, epoch_history],\n",
    "                         validation_steps = math.ceil(params[\"test_size\"]  / params[\"batch_size\"]))\n",
    "                   \n",
    "            final_history = defaultdict(list)\n",
    "\n",
    "            for d in (history.history, history1.history): # you can list as many input dicts as you want here\n",
    "                for key, value in d.items():\n",
    "                    for t in value:\n",
    "                        final_history[key].append(t)\n",
    "            with open(params[\"historypath\"] + \"/history.json\", \"w\") as f:\n",
    "                json.dump(final_history, f)  \n",
    "                \n",
    "            if (history1.history['val_acc'][-1] > best_accuracy):\n",
    "                best_accuracy = history1.history['val_acc'][-1]\n",
    "                model.save(\"model_\" + params[\"model\"] + \".h5\")\n",
    "                with open(params[\"model\"] +\"_history.json\", \"w\") as f:\n",
    "                    json.dump(final_history, f)                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
